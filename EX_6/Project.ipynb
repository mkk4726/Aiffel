{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6748dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.3.3\n",
      "1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import pandas\n",
    "\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(pandas.__version__)\n",
    "print(version('summa'))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28f5f3",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc20c783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>Indira Gandhi proved her mettle without quota:...</td>\n",
       "      <td>Union Minister Nitin Gadkari on Monday lauded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78938</th>\n",
       "      <td>In Pics: School by B'luru couple for construct...</td>\n",
       "      <td>A Bengaluru couple has reportedly started 'Diy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65012</th>\n",
       "      <td>Flipkart in talks to buy stake in Future Group...</td>\n",
       "      <td>E-commerce major Flipkart is in talks with Fut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45191</th>\n",
       "      <td>Ã¢ÂÂ¹26,000 phone that only allows calls, mes...</td>\n",
       "      <td>US-based company Light has developed a Ã¢ÂÂ¹2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>7-year-old girl raped on neighbour's terrace i...</td>\n",
       "      <td>A seven-year-old girl was allegedly raped by a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77768</th>\n",
       "      <td>Indian Army team participates in tank race in ...</td>\n",
       "      <td>An Indian Army team has participated in a tank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32387</th>\n",
       "      <td>Buffett very good at doing nothing: Berkshire ...</td>\n",
       "      <td>Talking about Berkshire Hathaway Chairman and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67771</th>\n",
       "      <td>Baby dies due to lack of ventilators in Delhi ...</td>\n",
       "      <td>A newborn baby died on Wednesday allegedly due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74453</th>\n",
       "      <td>Andhra doc tries to inject senior with HIV-inf...</td>\n",
       "      <td>A doctor at Andhra Pradesh's Proddatur Governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98250</th>\n",
       "      <td>Union Cabinet approves National Health Policy</td>\n",
       "      <td>The Union Cabinet on Wednesday approved the Na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "3178   Indira Gandhi proved her mettle without quota:...   \n",
       "78938  In Pics: School by B'luru couple for construct...   \n",
       "65012  Flipkart in talks to buy stake in Future Group...   \n",
       "45191  Ã¢ÂÂ¹26,000 phone that only allows calls, mes...   \n",
       "5452   7-year-old girl raped on neighbour's terrace i...   \n",
       "77768  Indian Army team participates in tank race in ...   \n",
       "32387  Buffett very good at doing nothing: Berkshire ...   \n",
       "67771  Baby dies due to lack of ventilators in Delhi ...   \n",
       "74453  Andhra doc tries to inject senior with HIV-inf...   \n",
       "98250      Union Cabinet approves National Health Policy   \n",
       "\n",
       "                                                    text  \n",
       "3178   Union Minister Nitin Gadkari on Monday lauded ...  \n",
       "78938  A Bengaluru couple has reportedly started 'Diy...  \n",
       "65012  E-commerce major Flipkart is in talks with Fut...  \n",
       "45191  US-based company Light has developed a Ã¢ÂÂ¹2...  \n",
       "5452   A seven-year-old girl was allegedly raped by a...  \n",
       "77768  An Indian Army team has participated in a tank...  \n",
       "32387  Talking about Berkshire Hathaway Chairman and ...  \n",
       "67771  A newborn baby died on Wednesday allegedly due...  \n",
       "74453  A doctor at Andhra Pradesh's Proddatur Governm...  \n",
       "98250  The Union Cabinet on Wednesday approved the Na...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "data.sample(10)\n",
    "\n",
    "# headline -> 요약된 문장\n",
    "# text -> 전체 문장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0602f141",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c811697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 데이터 제거\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "# null 제거\n",
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9c8795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 정규화 사전 정의\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "661d01bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentenc e) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a2f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1834f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98360/98360 [09:25<00:00, 174.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98360 98360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98360/98360 [01:59<00:00, 820.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98360 98360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# text 전처리하기\n",
    "\n",
    "clean_text = []\n",
    "\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    result = preprocess_sentence(data['text'].values[i])\n",
    "    clean_text.append(result)\n",
    "    \n",
    "print(len(clean_text), data.shape[0])\n",
    "\n",
    "# headlines 전처리하기 \n",
    "\n",
    "clean_summary = []\n",
    "\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    result = preprocess_sentence(data['headlines'].values[i])\n",
    "    clean_summary.append(result)\n",
    "    \n",
    "print(len(clean_summary), data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d098467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')\n",
    "# null 제거\n",
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8baea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# with open('./data/data.pickle', 'wb') as f:\n",
    "#     pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# load\n",
    "with open('./data/data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3deb9022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 45 이하인 샘플의 비율: 0.9967771451809678\n",
      "전체 샘플 중 길이가 10 이하인 샘플의 비율: 0.9978344855632371\n"
     ]
    }
   ],
   "source": [
    "# max len 정하기\n",
    "text_max_len = 45\n",
    "summary_max_len = 10\n",
    "# 수작업으로 세주기\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(summary_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab717f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 자르기\n",
    "data['text'] = data['text'].apply(lambda x: x if len(x.split()) <= text_max_len else np.nan)\n",
    "data['headlines'] = data['headlines'].apply(lambda x: x if len(x.split()) <= summary_max_len else np.nan)\n",
    "\n",
    "data = data.dropna()\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e485907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19568\n"
     ]
    }
   ],
   "source": [
    "# split tr / ts\n",
    "\n",
    "n_of_val = int(len(encoder_input)  *0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f457f875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 67794\n",
      "등장 빈도가 4번 이하인 희귀 단어의 수: 41837\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 25957\n",
      "단어 집합에서 희귀 단어의 비율: 61.71195091011003\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.605083117454884\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합(vocabulary) 만들기\n",
    "\n",
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "\n",
    "# 빈도수 낮은 애들 빼주자\n",
    "threshold = 5\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "\n",
    "src_vocab = 25957 # 전체 중 3프로 밖에 해당하지 않는 74%의 희귀 단어를 제외했을 때의 단어 집합의 크기\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d916e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80c40970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 78276\n",
      "훈련 레이블의 개수 : 78276\n",
      "테스트 데이터의 개수 : 19568\n",
      "테스트 레이블의 개수 : 19568\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "479e5b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# Padding 하기\n",
    "\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845abcb",
   "metadata": {},
   "source": [
    "# Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9c340f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len, ))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c21e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(src_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h3, state_c3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3252a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 128)      3322496     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    3322496     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 25957)  6670949     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 15,155,045\n",
      "Trainable params: 15,155,045\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(src_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "650192fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tar_vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40/1683375311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 디코더의 출력층\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdecoder_softmax_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdecoder_softmax_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_softmax_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_concat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tar_vocab' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_output3])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ae91d",
   "metadata": {},
   "source": [
    "## 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "110f5151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "306/306 [==============================] - 35s 92ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "306/306 [==============================] - 27s 88ms/step - loss: nan - val_loss: nan\n",
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad2c18d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e2e713",
   "metadata": {},
   "source": [
    "# Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83d2776f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attn_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40/2959570820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 어텐션 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdecoder_hidden_state_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mattn_out_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_outputs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden_state_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mdecoder_inf_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_outputs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_out_inf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attn_layer' is not defined"
     ]
    }
   ],
   "source": [
    "# inferece 모델 구축\n",
    "\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_output3, state_h3, state_c3])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c9d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8fd4ce5",
   "metadata": {},
   "source": [
    "# Step 5. Summa을 이용해서 추출적 요약해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e188a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5418e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617ab23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b8198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41f94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7af594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae866038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e36302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
